# Lessons Learnt

1) The dataset that we used for this project is curated to represent diagnostic decision geometry rather than population prevalence. However in order to study the impact of geometry on an imbalanced data set, we can make use of a perturbed data set which we had attempted in this project as well (covered in Appendix).
2) Accuracy metrics need to be studied in conjunction with impact. False Negatives reported by a classifier need more focus when we analyze diagnosis of a fatal disease like cancer.
3) Logistic regression behaves like a distribution-sensitive estimator, influenced by the entire likelihood structure, whereas linear SVC is margin-driven and influenced primarily by boundary cases.
They both complement each other to gain a first-hand understanding about the boundary – whether it is margin-driven or probability-driven.
4) LDA is based on distributional assumptions (Gaussian classes with equal covariance) and hence was kept out of scope for this project. This project deals with geometry under various modeling approaches and aims to pick the most representative one.
5) LinearSVC and SVC(kernel=’linear’) are essentially not identical implementations since they differ in optimization method, regularization form and on use of support vectors. However, for a small dataset that we consider they both may give only similar results. For the sake of consistency and coding standardization we used SVC variants (linear, polynomial, RBF) all under the same libsvm framework.
6) When we need more number of principal components to optimize accuracy, we may not be able to look at the impact of PCA visually. However, it would make sense to pick up the first two principal components alone to get a sense of the representational capacity though it may not be useful for model choice.
7) Representation quality is not about picking “big” features. It is about how features combine directionally. We understood this by comparing a transformation of dataset with manually selected features against PCA transformation.
8) When we use polynomial SVC, degree 3 is an appropriate choice to begin with because it introduces moderate nonlinearity. Degree 2 can model only simple curved boundaries while higher degrees may quickly become numerically unstable and overfit small datasets.
9) When we try to work with a perturbed dataset for a classification problem, it is important to modify the number of rows – either add / reduce from the earlier dataset. Changing class labels for some of the records would amount to label distortion and may produce lopsided results during experimentation.
